{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aabf7c-1e04-460a-b861-e052d85d7df8",
   "metadata": {},
   "source": [
    "# Get accuracy and F1 for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f69259e-92aa-4810-9fae-f17b204c35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import io\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b4094-cd8b-4d43-ab4f-e1f847dc46a3",
   "metadata": {},
   "source": [
    "## from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4128cb-a2e7-4f39-952c-05a0b1803444",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=pd.read_csv(\"./test_yelp_1k.csv\")\n",
    "gpt3=pd.read_csv(\"./text-davinci-003_test_1k.csv\")\n",
    "llama=pd.read_csv(\"./pkl_pred/llama7b_test_1k.csv\")\n",
    "alpaca=pd.read_csv(\"./pkl_pred/alpaca7b_plain_test_1k.csv\")\n",
    "gpt2=pd.read_csv(\"./pkl_pred/gpt2xl_test_1k.csv\")\n",
    "gpt35=pd.read_csv(\"./gpt-3.5-turbo_test_1k.csv\")\n",
    "df_subsets=pd.read_csv(\"./test_1k_subsets.csv\")\n",
    "gpt4=pd.read_csv(\"./gpt-4_test_1k.csv\")\n",
    "prompts=pd.read_csv(\"./prompts_test_1k.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3c5519-23d0-427e-8d33-ed386a1d020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prediction(df,start=None,end=None):\n",
    "    if start:\n",
    "        df['pred_label']=df.pred.str[start:]\n",
    "    elif end:\n",
    "        df['pred_label']=df.pred.str[:end]\n",
    "    else:\n",
    "        df['pred_label']=df.pred\n",
    "    df['pred_label'] = df['pred_label'].str.replace(\"one\",\"1\").replace(\"two\",\"2\").replace(\"three\",\"3\").replace(\"four\",\"4\").replace(\"five\",\"5\")\n",
    "    df['pred_label'] = df['pred_label'].str.extract(r'(\\d)')\n",
    "    #df['pred_label']=df['pred_label'].str.extract(r'(\\d+)')\n",
    "    #df=df.loc[df.pred_label.isin([\"1\",'2',\"3\",'4','5'])]\n",
    "    df['pred_label']=df['pred_label'].fillna(99)\n",
    "    df['pred_label']=df['pred_label'].apply(int)\n",
    "    df['pred_label']=df['pred_label']-1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa34c05-26f8-4851-9476-dbf847b12496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_prompt(df,prompts):\n",
    "    df=df.merge(prompts,on=['review_id','prompt_type','prompt_id'],how='left')\n",
    "    escaped_values = [re.escape(value) for value in df['prompt']]\n",
    "    pattern = '|'.join(escaped_values)\n",
    "    # Replace content of column2 with an empty string if it exists in column1\n",
    "    df['pred'] = df['pred'].str.replace(pattern, '', regex=True)\n",
    "    df=df.loc[:,['pred', 'review_id', 'prompt_type', 'prompt_id']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72c926-0171-4862-9786-c3c323652be5",
   "metadata": {},
   "source": [
    "## Clean predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe5ca4e-a300-4928-a466-02394fa22735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpaca['pred'] = alpaca['pred'].str.extract(r'### Response:(.*)')\n",
    "alpaca=replace_prompt(alpaca,prompts)\n",
    "\n",
    "llama=replace_prompt(llama,prompts)\n",
    "\n",
    "gpt2=replace_prompt(gpt2,prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1587d1fe-2812-4310-bf84-1d64995016e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca=parse_prediction(alpaca.copy(),end=45)\n",
    "llama=parse_prediction(llama.copy(),end=45)\n",
    "gpt2=parse_prediction(gpt2.copy(),end=15)\n",
    "gpt3=parse_prediction(gpt3.copy())\n",
    "gpt35=parse_prediction(gpt35.copy())\n",
    "gpt4=parse_prediction(gpt4.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a2a434-e240-425f-a048-629d5cb69820",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca=alpaca.loc[:,['review_id','prompt_type','prompt_id','pred_label']].rename(columns={'pred_label':'pred_alpaca'})\n",
    "llama=llama.loc[:,['review_id','prompt_type','prompt_id','pred_label']].rename(columns={'pred_label':'pred_llama'})\n",
    "gpt2=gpt2.loc[:,['review_id','prompt_type','prompt_id','pred_label']].rename(columns={'pred_label':'pred_gpt2'})\n",
    "gpt3=gpt3.loc[:,['review_id','prompt_type','prompt_id','pred_label']].rename(columns={'pred_label':'pred_gpt3'})\n",
    "gpt35=gpt35.loc[:,['review_id','prompt_type','prompt_id','pred_label']].rename(columns={'pred_label':'pred_gpt35'})\n",
    "gpt4=gpt4.loc[:,['review_id','prompt_type','prompt_id','pred_label']].rename(columns={'pred_label':'pred_gpt4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00d5a4a8-6277-4af7-ad24-b4e64ab597dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred=gpt3.merge(gpt2,on=['review_id','prompt_type','prompt_id'],how='outer').merge(llama,on=['review_id','prompt_type','prompt_id'],how='outer').merge(alpaca,on=['review_id','prompt_type','prompt_id'],how='outer').merge(gpt35,on=['review_id','prompt_type','prompt_id'],how='outer').merge(gpt4,on=['review_id','prompt_type','prompt_id'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69be2917-4008-4b32-9d59-221e3571f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.merge(all_pred,on=['review_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29cb7c9-fea5-4b5a-8f6c-14af8980c3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60790294-e19d-426c-b9df-9d4b1fcdcb95",
   "metadata": {},
   "source": [
    "## get info subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f14eab9-59fa-49c8-b3e4-7e933ce290c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.merge(df_subsets,on='review_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dadb9a4-e94a-4954-b7be-c380a00a172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 0\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "random_values = np.random.randint(0, 5, size=test_set.shape[0])\n",
    "\n",
    "test_set['pred_random']=random_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3058de-c59e-45a7-b03e-21d0b4cbac70",
   "metadata": {},
   "source": [
    "### gpt2_proba\n",
    "- for gpt2 get probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87aa5b6d-72a7-4649-95a9-67b3877e488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "\n",
    "def get_key_with_max_value(dictionary):\n",
    "    try:\n",
    "        key=max(dictionary, key=dictionary.get)\n",
    "    except:\n",
    "        print(dictionary)\n",
    "        return None\n",
    "    return key\n",
    "\n",
    "def get_key_with_max_value_options(dictionary):\n",
    "    try:\n",
    "        new_dict={}\n",
    "        new_dict[' 1']=dictionary.get('1',0)+dictionary.get(' 1',0)+dictionary.get('one',0)+dictionary.get(' one',0)\n",
    "        new_dict[' 2']=dictionary.get('2',0)+dictionary.get(' 2',0)+dictionary.get('two',0)+dictionary.get(' two',0)\n",
    "        new_dict[' 3']=dictionary.get('3',0)+dictionary.get(' 3',0)+dictionary.get('three',0)+dictionary.get(' three',0)\n",
    "        new_dict[' 4']=dictionary.get('4',0)+dictionary.get(' 4',0)+dictionary.get('four',0)+dictionary.get(' four',0)\n",
    "        new_dict[' 5']=dictionary.get('5',0)+dictionary.get(' 5',0)+dictionary.get('five',0)+dictionary.get(' five',0)\n",
    "        key=max(new_dict, key=new_dict.get)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(dictionary)\n",
    "        return None\n",
    "    return key\n",
    "\n",
    "def get_key_value_with_max_value(dictionary):\n",
    "    max_key = max(dictionary, key=dictionary.get)\n",
    "    max_value = dictionary[max_key]\n",
    "    return max_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e73caee-92d8-4802-8960-47184281a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pkl_pred/res_gpt2xl_test_1k.pkl', 'rb') as file:\n",
    "    #res_c1 = pickle.load(file)\n",
    "    contents = CPU_Unpickler(file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71f2e28e-267c-4de7-9353-1b88daf09b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses=pd.DataFrame(contents)\n",
    "\n",
    "gt=test_set.loc[:,['review_id','prompt_type', 'prompt_id','label']].copy()\n",
    "\n",
    "responses=gt.merge(responses,on=['review_id','prompt_type', 'prompt_id'],how='left')\n",
    "\n",
    "p0=responses.probas_0.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48195931-ba09-478d-a184-d7117ce55cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n",
      "'float' object has no attribute 'get'\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "responses['max_value_0'] = responses['probas_0'].apply(lambda x: get_key_with_max_value_options(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a432e580-5508-445e-84fa-0d531f481e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "map={' 1':1, ' 5':5, ' 3':3, ' 4':4, ' 2':2, ' one':1, ' five':5, ' three':3,' four':4, ' two':2}\n",
    "\n",
    "responses['pred_gpt2_proba']=responses['max_value_0'].map(map)\n",
    "responses['pred_gpt2_proba']=responses['pred_gpt2_proba'].fillna(99)\n",
    "responses['pred_gpt2_proba']=responses['pred_gpt2_proba'].apply(int)\n",
    "responses['pred_gpt2_proba']=responses['pred_gpt2_proba']-1\n",
    "\n",
    "responses_proba_gpt=responses.loc[:,['review_id','prompt_type', 'prompt_id','pred_gpt2_proba']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41284bbf-f171-41c3-adb4-23b60f34c26d",
   "metadata": {},
   "source": [
    "## Predictions prompt c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db285833-26c8-4115-a887-aef3214019bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.merge(responses_proba_gpt,on=['review_id','prompt_type','prompt_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2cf31f-1961-4e0b-8074-aea78060f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df=test_set.loc[test_set.prompt_type==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784e8ec-7a3e-495b-9497-2c3ddfb339f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "f1s=[]\n",
    "models=[]\n",
    "prompt_ids=[]\n",
    "for model in [\"random\",\"gpt2\",\"gpt3\",\"llama\",\"alpaca\",\"gpt35\",\"gpt4\",\"gpt2_proba\"]:\n",
    "    for prompt_id in [0,1,2,3,4]:\n",
    "        print(\"prompt_id \",prompt_id)\n",
    "        df_temp=working_df.loc[( (working_df.prompt_id==prompt_id)& (working_df['pred_'+model].isin([0,1,2,3,4])))]\n",
    "        print(model)\n",
    "        print(classification_report(df_temp.label,df_temp['pred_'+model]))\n",
    "        rep=classification_report(df_temp.label,df_temp['pred_'+model],output_dict=True,digits=4)\n",
    "        accuracies.append(rep['accuracy']*100)\n",
    "        f1s.append(rep['weighted avg']['f1-score']*100)\n",
    "        models.append(model)\n",
    "        prompt_ids.append(prompt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6885ba4c-3378-4765-8cfe-ecf6d27ac269",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'model':models,'prompt_id':prompt_ids,'accuracy':accuracies,'f1':f1s}\n",
    "results_df=pd.DataFrame(results)\n",
    "\n",
    "results_df=results_df.groupby(['model']).agg({'accuracy':[np.mean,np.std],'f1':[np.mean,np.std]})\n",
    "\n",
    "results_df=round(results_df,2)\n",
    "\n",
    "results_df.columns =['_'.join(col) for col in results_df.columns]\n",
    "\n",
    "results_df=results_df.reset_index()\n",
    "order={\"random\":0,'gpt2_proba':1,'llama':2,'alpaca':3,'gpt3':4,'gpt35':5,'gpt4':6,'gpt2':11,\"llama13\":12}\n",
    "results_df['order']=results_df.model.map(order)\n",
    "results_df=results_df.sort_values('order')\n",
    "table = results_df.apply(lambda x: \"{:.2f} {{\\\\tiny$\\pm${:.2f}}}\".format(x['accuracy_mean'], x['accuracy_std']), axis=1)\n",
    "\n",
    "table_f1 = results_df.apply(lambda x: \"{:.2f} {{\\\\tiny$\\pm${:.2f}}}\".format(x['f1_mean'], x['f1_std']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3be04489-6322-45c0-a19b-d62d35bf8450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random</td>\n",
       "      <td>19.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>19.86</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2_proba</td>\n",
       "      <td>23.06</td>\n",
       "      <td>2.10</td>\n",
       "      <td>10.23</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama</td>\n",
       "      <td>39.28</td>\n",
       "      <td>5.07</td>\n",
       "      <td>31.78</td>\n",
       "      <td>5.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca</td>\n",
       "      <td>47.72</td>\n",
       "      <td>4.19</td>\n",
       "      <td>46.01</td>\n",
       "      <td>5.35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3</td>\n",
       "      <td>53.22</td>\n",
       "      <td>1.35</td>\n",
       "      <td>52.71</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt35</td>\n",
       "      <td>58.36</td>\n",
       "      <td>4.13</td>\n",
       "      <td>57.98</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>59.84</td>\n",
       "      <td>4.17</td>\n",
       "      <td>59.54</td>\n",
       "      <td>4.69</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>22.89</td>\n",
       "      <td>2.20</td>\n",
       "      <td>10.26</td>\n",
       "      <td>3.81</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy_mean  accuracy_std  f1_mean  f1_std  order\n",
       "7      random          19.84          0.54    19.86    0.60      0\n",
       "2  gpt2_proba          23.06          2.10    10.23    4.12      1\n",
       "6       llama          39.28          5.07    31.78    5.32      2\n",
       "0      alpaca          47.72          4.19    46.01    5.35      3\n",
       "3        gpt3          53.22          1.35    52.71    1.73      4\n",
       "4       gpt35          58.36          4.13    57.98    5.11      5\n",
       "5        gpt4          59.84          4.17    59.54    4.69      6\n",
       "1        gpt2          22.89          2.20    10.26    3.81     11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d3c877-5d6c-4511-a3f2-1fa26b659a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.86 {\\tiny$\\pm$0.60} & 10.23 {\\tiny$\\pm$4.12} & 31.78 {\\tiny$\\pm$5.32} & 46.01 {\\tiny$\\pm$5.35} & 52.71 {\\tiny$\\pm$1.73} & 57.98 {\\tiny$\\pm$5.11} & 59.54 {\\tiny$\\pm$4.69} & 10.26 {\\tiny$\\pm$3.81}\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(table_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a796977-6bf0-46b5-9d2a-64438f1a6a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.84 {\\tiny$\\pm$0.54} & 23.06 {\\tiny$\\pm$2.10} & 39.28 {\\tiny$\\pm$5.07} & 47.72 {\\tiny$\\pm$4.19} & 53.22 {\\tiny$\\pm$1.35} & 58.36 {\\tiny$\\pm$4.13} & 59.84 {\\tiny$\\pm$4.17} & 22.89 {\\tiny$\\pm$2.20}\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781ef54-d4f5-490d-ab51-fe577a87ea34",
   "metadata": {},
   "source": [
    "## results by subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a8aac71-62e9-4deb-9734-279768a0bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_c1=test_set.loc[((test_set.pred_class=='C1') & (test_set.prompt_type==0)),:]\n",
    "test_set_c2=test_set.loc[((test_set.pred_class=='C2') & (test_set.prompt_type==0)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c886701-0dee-40bd-9ab1-6c75b4274d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_sub=test_set_c2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aaa7df-2a10-484a-ac3d-adec381daf7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "f1s=[]\n",
    "models=[]\n",
    "prompt_ids=[]\n",
    "for model in [\"random\",\"gpt2\",\"gpt3\",\"llama\",\"alpaca\",\"gpt35\",\"gpt4\",\"gpt2_proba\"]:\n",
    "    for prompt_id in [0,1,2,3,4]:\n",
    "        print(\"prompt_id \",prompt_id)\n",
    "        df_temp=working_df_sub.loc[( (working_df_sub.prompt_id==prompt_id)& (working_df_sub['pred_'+model].isin([0,1,2,3,4])))]\n",
    "        print(model)\n",
    "        print(classification_report(df_temp.label,df_temp['pred_'+model]))\n",
    "        rep=classification_report(df_temp.label,df_temp['pred_'+model],output_dict=True,digits=4)\n",
    "        accuracies.append(rep['accuracy']*100)\n",
    "        f1s.append(rep['weighted avg']['f1-score']*100)\n",
    "        models.append(model)\n",
    "        prompt_ids.append(prompt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91986db2-e527-4300-aec9-b99a0268709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'model':models,'prompt_id':prompt_ids,'accuracy':accuracies,'f1':f1s}\n",
    "results_df=pd.DataFrame(results)\n",
    "\n",
    "results_df=results_df.groupby(['model']).agg({'accuracy':[np.mean,np.std],'f1':[np.mean,np.std]})\n",
    "\n",
    "results_df=round(results_df,2)\n",
    "\n",
    "results_df.columns =['_'.join(col) for col in results_df.columns]\n",
    "\n",
    "results_df=results_df.reset_index()\n",
    "order={\"random\":0,'gpt2_proba':1,'llama':2,'alpaca':3,'gpt3':4,'gpt35':5,'gpt4':6,'gpt2':11,\"llama13\":12}\n",
    "results_df['order']=results_df.model.map(order)\n",
    "results_df=results_df.sort_values('order')\n",
    "table = results_df.apply(lambda x: \"{:.2f} {{\\\\tiny$\\pm${:.2f}}}\".format(x['accuracy_mean'], x['accuracy_std']), axis=1)\n",
    "\n",
    "table_f1 = results_df.apply(lambda x: \"{:.2f} {{\\\\tiny$\\pm${:.2f}}}\".format(x['f1_mean'], x['f1_std']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24e4f0b8-8895-4235-9214-1c24fc92c79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random</td>\n",
       "      <td>19.85</td>\n",
       "      <td>1.92</td>\n",
       "      <td>20.69</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2_proba</td>\n",
       "      <td>27.09</td>\n",
       "      <td>2.59</td>\n",
       "      <td>13.43</td>\n",
       "      <td>5.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama</td>\n",
       "      <td>37.40</td>\n",
       "      <td>6.34</td>\n",
       "      <td>31.44</td>\n",
       "      <td>6.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca</td>\n",
       "      <td>49.22</td>\n",
       "      <td>4.73</td>\n",
       "      <td>50.06</td>\n",
       "      <td>5.19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3</td>\n",
       "      <td>61.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>62.77</td>\n",
       "      <td>1.03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt35</td>\n",
       "      <td>55.81</td>\n",
       "      <td>6.65</td>\n",
       "      <td>57.18</td>\n",
       "      <td>7.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>58.78</td>\n",
       "      <td>6.36</td>\n",
       "      <td>60.38</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>26.99</td>\n",
       "      <td>2.56</td>\n",
       "      <td>13.66</td>\n",
       "      <td>4.58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy_mean  accuracy_std  f1_mean  f1_std  order\n",
       "7      random          19.85          1.92    20.69    2.04      0\n",
       "2  gpt2_proba          27.09          2.59    13.43    5.08      1\n",
       "6       llama          37.40          6.34    31.44    6.31      2\n",
       "0      alpaca          49.22          4.73    50.06    5.19      3\n",
       "3        gpt3          61.89          1.00    62.77    1.03      4\n",
       "4       gpt35          55.81          6.65    57.18    7.70      5\n",
       "5        gpt4          58.78          6.36    60.38    6.42      6\n",
       "1        gpt2          26.99          2.56    13.66    4.58     11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68db4ff3-4b98-42bb-b0b5-1bbb0caa66ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.69 {\\tiny$\\pm$2.04} & 13.43 {\\tiny$\\pm$5.08} & 31.44 {\\tiny$\\pm$6.31} & 50.06 {\\tiny$\\pm$5.19} & 62.77 {\\tiny$\\pm$1.03} & 57.18 {\\tiny$\\pm$7.70} & 60.38 {\\tiny$\\pm$6.42} & 13.66 {\\tiny$\\pm$4.58}\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(table_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b7cf60c-dcd9-44b6-88d7-bb6926620892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.85 {\\tiny$\\pm$1.92} & 27.09 {\\tiny$\\pm$2.59} & 37.40 {\\tiny$\\pm$6.34} & 49.22 {\\tiny$\\pm$4.73} & 61.89 {\\tiny$\\pm$1.00} & 55.81 {\\tiny$\\pm$6.65} & 58.78 {\\tiny$\\pm$6.36} & 26.99 {\\tiny$\\pm$2.56}\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ee506-f099-4bb6-838e-8f32dfe5e69d",
   "metadata": {},
   "source": [
    "## prompt c1 & c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58e6faa3-e0e8-44f7-a19b-70d183d1266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsets_500=df_subsets.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d7fd675-a08f-46f3-9151-36af00be4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_c1=test_set.loc[((test_set.pred_class=='C1') & (test_set.prompt_type==2)),:]\n",
    "test_set_c2=test_set.loc[((test_set.pred_class=='C2') & (test_set.prompt_type==2)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "868c6d58-aeb0-4950-9515-33a42e2fa166",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_sub=test_set_c1.loc[test_set_c1.review_id.isin(df_subsets_500.review_id.unique())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bc7a4-289a-44ae-9858-283d9c3a3a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "f1s=[]\n",
    "models=[]\n",
    "prompt_ids=[]\n",
    "for model in [\"random\",\"gpt2\",\"gpt3\",\"llama\",\"alpaca\",\"gpt35\",\"gpt4\",\"gpt2_proba\"]:\n",
    "    for prompt_id in [0,1,2,3,4]:\n",
    "        print(\"prompt_id \",prompt_id)\n",
    "        df_temp=working_df_sub.loc[( (working_df_sub.prompt_id==prompt_id)& (working_df_sub['pred_'+model].isin([0,1,2,3,4])))]\n",
    "        print(model)\n",
    "        print(classification_report(df_temp.label,df_temp['pred_'+model]))\n",
    "        rep=classification_report(df_temp.label,df_temp['pred_'+model],output_dict=True,digits=4)\n",
    "        accuracies.append(rep['accuracy']*100)\n",
    "        f1s.append(rep['weighted avg']['f1-score']*100)\n",
    "        models.append(model)\n",
    "        prompt_ids.append(prompt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "648c6f85-a05d-4dba-9391-49cb911f2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'model':models,'prompt_id':prompt_ids,'accuracy':accuracies,'f1':f1s}\n",
    "results_df=pd.DataFrame(results)\n",
    "\n",
    "results_df=results_df.groupby(['model']).agg({'accuracy':[np.mean,np.std],'f1':[np.mean,np.std]})\n",
    "\n",
    "results_df=round(results_df,2)\n",
    "\n",
    "results_df.columns =['_'.join(col) for col in results_df.columns]\n",
    "\n",
    "results_df=results_df.reset_index()\n",
    "order={\"random\":0,'gpt2_proba':1,'llama':2,'alpaca':3,'gpt3':4,'gpt35':5,'gpt4':6,'gpt2':11,\"llama13\":12}\n",
    "results_df['order']=results_df.model.map(order)\n",
    "results_df=results_df.sort_values('order')\n",
    "table = results_df.apply(lambda x: \"{:.2f} {{\\\\tiny$\\pm${:.2f}}}\".format(x['accuracy_mean'], x['accuracy_std']), axis=1)\n",
    "\n",
    "table_f1 = results_df.apply(lambda x: \"{:.2f} {{\\\\tiny$\\pm${:.2f}}}\".format(x['f1_mean'], x['f1_std']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c0419e2-ecf0-4dea-b252-5869016e69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random</td>\n",
       "      <td>19.73</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.17</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2_proba</td>\n",
       "      <td>25.69</td>\n",
       "      <td>6.74</td>\n",
       "      <td>18.91</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama</td>\n",
       "      <td>48.32</td>\n",
       "      <td>8.38</td>\n",
       "      <td>41.83</td>\n",
       "      <td>8.77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca</td>\n",
       "      <td>46.74</td>\n",
       "      <td>3.80</td>\n",
       "      <td>41.26</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3</td>\n",
       "      <td>59.80</td>\n",
       "      <td>1.92</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt35</td>\n",
       "      <td>55.01</td>\n",
       "      <td>5.99</td>\n",
       "      <td>54.38</td>\n",
       "      <td>6.43</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>60.13</td>\n",
       "      <td>3.27</td>\n",
       "      <td>59.96</td>\n",
       "      <td>2.92</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>30.35</td>\n",
       "      <td>5.53</td>\n",
       "      <td>21.51</td>\n",
       "      <td>4.35</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy_mean  accuracy_std  f1_mean  f1_std  order\n",
       "7      random          19.73          2.10    20.17    2.30      0\n",
       "2  gpt2_proba          25.69          6.74    18.91    4.95      1\n",
       "6       llama          48.32          8.38    41.83    8.77      2\n",
       "0      alpaca          46.74          3.80    41.26    4.36      3\n",
       "3        gpt3          59.80          1.92    57.82    1.11      4\n",
       "4       gpt35          55.01          5.99    54.38    6.43      5\n",
       "5        gpt4          60.13          3.27    59.96    2.92      6\n",
       "1        gpt2          30.35          5.53    21.51    4.35     11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80225bef-a352-4e92-8a42-b394b6dc6711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.17 {\\tiny$\\pm$2.30} & 18.91 {\\tiny$\\pm$4.95} & 41.83 {\\tiny$\\pm$8.77} & 41.26 {\\tiny$\\pm$4.36} & 57.82 {\\tiny$\\pm$1.11} & 54.38 {\\tiny$\\pm$6.43} & 59.96 {\\tiny$\\pm$2.92} & 21.51 {\\tiny$\\pm$4.35}\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(table_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecd5a28f-0ef2-49a9-93fa-73eb6f02ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.73 {\\tiny$\\pm$2.10} & 25.69 {\\tiny$\\pm$6.74} & 48.32 {\\tiny$\\pm$8.38} & 46.74 {\\tiny$\\pm$3.80} & 59.80 {\\tiny$\\pm$1.92} & 55.01 {\\tiny$\\pm$5.99} & 60.13 {\\tiny$\\pm$3.27} & 30.35 {\\tiny$\\pm$5.53}\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10654c84-a037-4dfe-8a31-bc151bed760d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
